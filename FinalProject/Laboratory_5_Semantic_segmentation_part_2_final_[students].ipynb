{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIlMQWUiUqxO"
   },
   "source": [
    "# Computer vision and deep learning - Laboratory 5\n",
    "\n",
    "In this laboratory, you will continue the semantic segmentation mini-project that we started last time. More specifically, you will write the CNN architecture, define the training loop, perform hyperparameter search and evaluate the best segmentation module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYMNqbIyVx0R",
    "outputId": "5c4bb4bc-c33d-4707-ad2d-9f8d85cf07c0",
    "ExecuteTime": {
     "end_time": "2024-01-18T17:12:54.835993100Z",
     "start_time": "2024-01-18T17:12:50.898023600Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install wget\n",
    "# !pip install wandb -qU\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import wget\n",
    "import glob\n",
    "import wandb\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JomB7EzTgbpe",
    "outputId": "6bf4a7ee-0d59-4c6d-a542-3e9737fc8992",
    "ExecuteTime": {
     "end_time": "2024-01-18T17:12:54.851601800Z",
     "start_time": "2024-01-18T17:12:54.835993100Z"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !mkdir 'cvdl_lab_4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BR0455RNghOB",
    "outputId": "e2952bcb-47bd-4c5c-c266-3728ac869b5c",
    "ExecuteTime": {
     "end_time": "2024-01-18T17:12:54.867240200Z",
     "start_time": "2024-01-18T17:12:54.851601800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#!cd cvdl_lab_4\n",
    "#!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cNuZRCCWBQo"
   },
   "source": [
    "## Building the model\n",
    "\n",
    "The model that will be used in this laboratory is inspired by the [U-Net](https://arxiv.org/abs/1505.04597) architecture.\n",
    "U-Net is a fully convolutional neural network comprising two symmetric paths: a contracting path (to capture context) and an expanding path  (which enables precise localization).\n",
    "The network also uses skip connections between the corresponding layers in the downsampling path to the layer in the upsampling path, and thus directly fast-forwards high-resolution feature maps from the encoder to the decoder network.\n",
    "\n",
    "The output of the model is an volume with depth C, where C is the number of pixel classes. For example, if you want to classify the pixels into person and background, the output will be a volume of depth 2.\n",
    "If you want to classify the pixels into face, hair and background the output will be a volume of depth 3.\n",
    "\n",
    "**Read the U-Net paper and try to understand the architecture.**\n",
    "\n",
    "An overview of the U-Net architecture is depicted in the figure below:\n",
    "<img src=\"https://miro.medium.com/max/1400/1*J3t2b65ufsl1x6caf6GiBA.png\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKKi5UowzvjZ"
   },
   "source": [
    "## The upsamping path\n",
    "\n",
    "\n",
    "In the upsampling path, we'll use transposed convolutions to progressively increase the resolution of the activation maps. The layers for the transposed convolution is [ConvTranspose2d](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html).\n",
    "\n",
    "Let's write a function to implement an upsampling block, consisting of a transposed convolution, a batch normalization block and a ReLu activation.\n",
    "\n",
    "Remember, the output size $W_o$ of a transposed convolutional layer is:  \n",
    "\\begin{equation}\n",
    "W_o = (W_i - 1) \\cdot S - 2P + F\n",
    "\\end{equation},\n",
    "\n",
    "where $W_i$ is the size of the input, $S$ is the stride, $P$ is the amount of padding and $F$ is the filter size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eAyhAkgfCM4O",
    "ExecuteTime": {
     "end_time": "2024-01-18T17:12:54.882867900Z",
     "start_time": "2024-01-18T17:12:54.867240200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def upsample_block(x, filters, size, stride = 2):\n",
    "  \"\"\"\n",
    "  x - the input of the upsample block\n",
    "  filters - the number of filters to be applied\n",
    "  size - the size of the filters\n",
    "  \"\"\"\n",
    "\n",
    "  # TODO your code here\n",
    "  # transposed convolution\n",
    "  # BN\n",
    "  # relu activation\n",
    "  conv_2d = torch.nn.Conv2d(x.shape[1], out_channels=filters, kernel_size=size, stride=stride, bias=False)\n",
    "  batch_norm_2d = torch.nn.BatchNorm2d(filters)\n",
    "  relu = torch.nn.ReLU(inplace=True)\n",
    "  \n",
    "  return relu(batch_norm_2d(conv_2d(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOg9FKZmj7dH"
   },
   "source": [
    "Now let's test this upsampling block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wDy7Qkzmj6Tv",
    "outputId": "c66b090f-2c73-4e44-ff57-4c9935227987",
    "ExecuteTime": {
     "end_time": "2024-01-18T17:12:55.023477200Z",
     "start_time": "2024-01-18T17:12:54.882867900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in shape:  torch.Size([32, 32, 128, 128])  upsample with filter size  4 ; stride  2  -> out shape  torch.Size([32, 16, 63, 63])\n",
      "in shape:  torch.Size([32, 32, 128, 128])  upsample with filter size  4 ; stride  4  -> out shape  torch.Size([32, 16, 32, 32])\n",
      "in shape:  torch.Size([32, 32, 128, 128])  upsample with filter size  4 ; stride  8  -> out shape  torch.Size([32, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "in_layer = torch.rand((32, 32, 128, 128))\n",
    "\n",
    "filter_sz = 4\n",
    "num_filters = 16\n",
    "\n",
    "for stride in [2, 4, 8]:\n",
    "  x = upsample_block(in_layer, num_filters, filter_sz, stride)\n",
    "  print('in shape: ', in_layer.shape, ' upsample with filter size ', filter_sz, '; stride ', stride, ' -> out shape ', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The down-sampling path\n",
    "\n",
    "\n",
    "For the down-sampling path we'll use a classical convolutional neural network.\n",
    "\n",
    "Write a class Encoder which inherits from ``torch.nn.Module`` for the down-sampling path. The model will be composed of several blocks, each block comprising two convolutional layers (with filter size of 3) with a ``ReLu`` non-linearity between them. The blocks of the encoder will be separated by max pooling layers with a size of 2 and a stride of 2.\n",
    "\n",
    " ![encoder.PNG](data:image/png;base64,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)\n",
    "\n",
    "In the constructor of the Encoder class you will pass as parameter a list containing the number of channels used for each encoder block. In the forward function you will return a list containing the outputs of all the encoder blocks (you’ll be using them for the connection between the down-sampling path and the up-sampling path).\n",
    "\n",
    "You can also use a pre-trained module from torchvision for this. You'll first load the pre-trained weights on ImageNet, and \"freeze\" these weights during the training process (set required_grad=False for those tensors). The problem is that to create the skip connections required by the U-Net architecture we need access to the feature maps of some intermediate layers in the network and these are not accessible by default.\n",
    "\n",
    "You should inspect the implementation of the CNN that you chose, make the Encoder class inherit from the model you chose, and in the forward function, return the output of the layers you selected for the skip connections.\n",
    "\n"
   ],
   "metadata": {
    "id": "5RyM2bNwkMqU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The up-sampling path (Decoder)\n",
    "\n",
    "In the upsampling path, we'll use transposed convolutions to progressively increase the resolution of the activation maps. The layers for the transposed convolution is [ConvTranspose2d](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html).\n",
    "\n",
    "Let's write a function to implement an upsampling block, consisting of a transposed convolution, a batch normalization block and a ReLu activation.\n",
    "\n",
    "Remember, the output size $W_o$ of a transposed convolutional layer is:  \n",
    "\\begin{equation}\n",
    "W_o = (W_i - 1) \\cdot S - 2P + F\n",
    "\\end{equation},\n",
    "\n",
    "where $W_i$ is the size of the input, $S$ is the stride, $P$ is the amount of padding and $F$ is the filter size.\n",
    "\n",
    "\n",
    "Similarly to the encoder, the decoder will be composed of several blocks, and each block will consist in a transposed convolution (followed by a batch normalization layer and a ReLU non-linearity) and then by an encoder block.  \n",
    "\n",
    " ![decoder.PNG](data:image/png;base64,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)\n",
    "\n",
    "Write a class Decoder  which inherits from ``torch.nn.Module`` to implement the up-samping path; the constructor of this class will get as parameter the depth of each decoder module, and in the forward function you will have two parameters: the input feature map and a list of activations from the encoder (for the skip connections).  \n",
    "\n",
    "\n",
    "\n",
    "In the forward function, for each block:\n",
    "\n",
    "- apply the up-sampling operation (followed by batch normalization and ReLU);\n",
    "\n",
    "- crop the corresponding activation map from the encoder (use CenterCrop) such that is has the same size as the decoder block;\n",
    "\n",
    "- concatenate these two activation maps (on the channel dimension);\n",
    "\n",
    "- apply an encoder block on the result;\n",
    "\n",
    "- pass the result to the next decoder block.\n",
    "\n"
   ],
   "metadata": {
    "id": "DxNuI5PClOkB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Putting it all together\n",
    "\n",
    "Finally, you should write the UNet class which defines the semantic segmentation model. In this class you will use and connect the Encoder and Decoder classes that you previously wrote. The output of the segmentation module will be a volume with as many channels as the number of classes from the segmentation problem. Basically, each channel c from the output will be a map that stores the probability of each pixel to belong to the class c.\n",
    "\n",
    "Apply a 1x1 convolution with c channels on the decoder output to obtain the segmentation map.\n",
    "\n",
    "Finally, to have matching shapes between the network output (segmentation map) and the ground truth data, resize the segmentation map using ``torch.nn.functional.interpolate``.\n",
    "\n",
    "\n",
    "### The training loop\n",
    "\n",
    "\n",
    "Now, it’s time to write the training loop.  \n",
    "\n",
    "You remember the steps from the previous labs. You need a train and a test DataLoader and you must first define the loss function BCELossWithLogits and select an optimizer.\n",
    "\n",
    "Then:\n",
    "\n",
    "- Get a batch of training data from the DataLoader\n",
    "- Zero out the optimizer’s gradients\n",
    "- Perform the forward pass\n",
    "- Calculate and store the loss and the accuracy based on the predictions and the labels from the dataset\n",
    "- Tell the optimizer to perform one learning step - that is, adjust the model’s learning weights based on the observed gradients for this batch, according to the optimization algorithm we chose\n",
    "- Evaluate the model on the validation/test set. Store the loss and the accuracy on the validation/test set."
   ],
   "metadata": {
    "id": "hh3gmb0HlmmW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation metrics\n",
    "\n",
    "Finally, you will implement several segmentation metrics to evaluate the model you've just trained. As usual, try to implement these metrics without using any for loops.\n",
    "\n",
    "In the remainder of this section we'll use the following notation:\n",
    "- $n_{ij}$ - the total number of pixels classified to class\n",
    "j but actually belonging to class i; $i, j \\in 1, .., C$;\n",
    "- $t_i = \\sum_{j = 1}^{C} n_{ij}$ - the total number of pixels belonging to class $i$ (in the ground truth segmentation mask);\n",
    "- $C$ - the total number of classes in the segmentation problem.\n",
    "\n",
    "### Mean pixel accuracy\n",
    "\n",
    "Pixel accuracy is the simplest image segmentation metric; it is defined as the percentage of pixels that were correctly classified by the model.\n",
    "\n",
    "\\begin{equation}\n",
    "p_a = \\frac{1}{C} \\frac{\\sum_{i}^{C} n_{ii}}{\\sum_{i}^{C} t_i}\n",
    "\\end{equation}\n",
    "\n",
    "This metric is not that relevant for class imbalanced problems (which occurs for most segmentation problems).\n",
    "\n",
    "### Intersection over Union (IoU)\n",
    "\n",
    "the intersection over union metric is defined as the ratio between the area of intersection and the area of union (between the predicted segmentation mask and the ground truth segmentation mask of a single class).\n",
    "In case of a multi-class segmentation problem, we simple average the IoUs over all the classes. This metric is called mean Intersection over Union (mIou).\n",
    "\n",
    "\\begin{equation}\n",
    "mIoU = \\frac{1}{C} \\sum_{i = 1}^{C} \\frac{n_{ii}}{t_i - n_{ii} + \\sum_{j = 1}^{C} n_{ji}}\n",
    "\\end{equation}\n",
    "\n",
    "The ideal value for this metric is 1; usually values lower than 0.6 indicate a very bad performance.\n",
    "\n",
    "### Frequency Weighted Intersection over Union\n",
    "\n",
    "The frequency weighted over union metric is similar to mean IoU, but the values are weighted with the adequate frequencies of the pixels.\n",
    "\n",
    "\\begin{equation}\n",
    "fIou = (\\sum_{i = 1}^{k} t_i)^{-1}   \\sum_{i = 1}^{C} t_i \\cdot \\frac{n_{ii}}{t_i - n_{ii} + \\sum_{j = 1}^{C} n_{ji}}\n",
    "\\end{equation}\n",
    "\n",
    "The values of this metric lie in the interval [0, 1], and the ideal value for this metric is 1.\n",
    "\n",
    "Compute and report these metrics for your trained model(s).\n",
    "\n"
   ],
   "metadata": {
    "id": "23OxRSYSmznF"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUXod31hAyFI"
   },
   "source": [
    "# Wandb\n",
    "Weights and Biases wandb is a machine learning experiment tracking and visualization tool which allows you to easily track, visualize, and collaborate on machine learning experiments. You will use wandb a to log and track various parameters, such as your hyperparameters, model performance metrics, data visualizations and system metrics.\n",
    "\n",
    "For now, just check out this tutorial on how you can easily integrate wandb with pytorch. Just look at the functions from wandb and how they are used, such that next time you hvae an ideea on how to structure your project.\n",
    "\n",
    "You will also use wandb sweeps to automate hyperparameter tuning. This module explores different combinations of hyperparameters to help users find the best configuration for their models. Sweep configurations can be defined using YAML files or programmatically in dictionaries, and wandb takes care of running multiple experiments with different parameter combinations, keeping track of results, and displaying them in a comprehensive dashboard for analysis.\n",
    "\n",
    "This time you will use [wandb](https://wandb.ai/) to track your experiments and perform hyperparameter search.\n",
    "\n",
    "\n",
    "1. Log the loss and several metrics after each epoch: use ``wandb.log()`` method within your training loop after each epoch to log the loss and at least two metrics on the train and the validation dataset.\n",
    "\n",
    "\n",
    "2. Use a ``wandb.Table`` to visualize the predictions on the validation dataset across the training process. You can find more details [here](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/datasets-predictions/W%26B_Tables_Quickstart.ipynb#scrollTo=tbOiat0mrWA2).\n",
    "\n",
    "\n",
    "3. [Artifacts](https://docs.wandb.ai/guides/artifacts/construct-an-artifact) are used to track and version any serialized data as the inputs and outputs.\n",
    "\n",
    "\n",
    "\"W&B Artifacts was designed to make it effortless to version your datasets and models, regardless of whether you want to store your files with W&B or whether you already have a bucket you want W&B to track. Once you've tracked your datasets or model files, W&B will automatically log each and every modification, giving you a complete and auditable history of changes to your files.\"\n",
    "\n",
    "\n",
    "Create a class ModelCheckpoint which will be responsible for tracking the best N checkpoints across the training process. This class will monitor a metric, and if the value for that metric is higher/lower (depending on whether the ) than the current max/min, it will save a checkpoint of the model.\n",
    "Also, you should ensure that at a given time only N checkpoints are being saved. So, if the number of saved checkpoints is greater than N, you should perform a cleanup.\n",
    "\n",
    "\n",
    "```\n",
    "    def __call__(self, model, epoch, metric_val):\n",
    "        must_save = metric_val < self.best_metric_val if self.decreasing_metric else metric_val > self.best_metric_val\n",
    "        if must_save:\n",
    "            self.best_metric_val = metric_val\n",
    "            # TODO use torch.save to save the model\n",
    "            # TODO use the function below to log the model artifact\n",
    "       \n",
    "        # TODO if needed, perform cleanup\n",
    "   \n",
    "    def write_artifact(self, path, model_path, metric_val):\n",
    "        artifact = wandb.Artifact(filename, type='model', metadata={'metric': metric_val})\n",
    "        artifact.add_file(model_path)\n",
    "        wandb.run.log_artifact(artifact)    \n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "4. You will also use [wandb sweeps](https://docs.wandb.ai/guides/sweeps) to automate hyperparameter tuning. This module explores different combinations of hyperparameters to help users find the best configuration for their models.\n",
    "\n",
    "[Here](https://www.youtube.com/watch?v=9zrmUIlScdY&ab_channel=Weights%26Biases) you can find a video tutorial on how you can use sweeps in wandb and [here](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb) the corresponding colab.\n",
    "\n",
    "\n",
    "Random Search is a hyperparameter optimization technique that involves randomly sampling hyperparameter values within specified ranges or distributions. It explores the hyperparameter space by selecting combinations randomly, allowing for a broad search across various configurations without following a specific pattern or grid.\n",
    "\n",
    "\n",
    "Grid Search is a method where hyperparameter values are exhaustively tested across a predefined grid or set of values. It evaluates the model's performance for each combination of hyperparameters within the specified ranges, systematically covering the entire search space to find the optimal configuration.\n",
    "\n",
    "\n",
    "Perform hyperparameter search using wandb sweeps (more details [here](https://wandb.ai/wandb_fc/articles/reports/Running-Hyperparameter-Sweeps-to-Pick-the-Best-Model--Vmlldzo1NDQ0OTIy)) for the learning rate and at least one other parameter.\n",
    "- first perform a random search as a preliminary exploration to identify \"promising\" values for your hyperparameters;\n",
    "- then apply a grid search on this range, to perform a more focused investigation into promising regions for finer optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m   Violation 1. Additional properties are not allowed ('transforms_brightness_and_contrast' was unexpected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 2o0fr12z\n",
      "Sweep URL: https://wandb.ai/soniamatei/wandb-experiment-sweep/sweeps/2o0fr12z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Agent Starting Run: 1gzf4ede with config:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbatch_size: 12\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tbrightness: 0.138399520743261\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tcontrast: 0.11278163068901163\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tepochs: 15\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \tlearning_rate: 0.008663091794691182\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33msoniamatei\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.1"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>D:\\Users\\sonia\\UBBy2\\CVDL\\FinalProject\\wandb\\run-20240118_191300-1gzf4ede</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/soniamatei/wandb-experiment-sweep/runs/1gzf4ede' target=\"_blank\">experiment-wandb-specialized</a></strong> to <a href='https://wandb.ai/soniamatei/wandb-experiment-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/soniamatei/wandb-experiment-sweep/sweeps/2o0fr12z' target=\"_blank\">https://wandb.ai/soniamatei/wandb-experiment-sweep/sweeps/2o0fr12z</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/soniamatei/wandb-experiment-sweep' target=\"_blank\">https://wandb.ai/soniamatei/wandb-experiment-sweep</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View sweep at <a href='https://wandb.ai/soniamatei/wandb-experiment-sweep/sweeps/2o0fr12z' target=\"_blank\">https://wandb.ai/soniamatei/wandb-experiment-sweep/sweeps/2o0fr12z</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/soniamatei/wandb-experiment-sweep/runs/1gzf4ede' target=\"_blank\">https://wandb.ai/soniamatei/wandb-experiment-sweep/runs/1gzf4ede</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "    Phase: train\n",
      "    Phase: validation\n",
      "    Phase: test\n",
      " Loss: 0.4527 Acc: 0.7126\n",
      "Epoch: 1\n",
      "    Phase: train\n",
      "    Phase: validation\n",
      "    Phase: test\n",
      " Loss: 0.3522 Acc: 0.7563\n",
      "Epoch: 2\n",
      "    Phase: train\n",
      "    Phase: validation\n",
      "    Phase: test\n",
      " Loss: 0.3230 Acc: 0.7697\n",
      "Epoch: 3\n",
      "    Phase: train\n",
      "    Phase: validation\n",
      "    Phase: test\n",
      " Loss: 0.2971 Acc: 0.7777\n",
      "Epoch: 4\n",
      "    Phase: train\n",
      "    Phase: validation\n",
      "    Phase: test\n",
      " Loss: 0.2860 Acc: 0.7839\n",
      "Epoch: 5\n",
      "    Phase: train\n",
      "    Phase: validation\n",
      "    Phase: test\n",
      " Loss: 0.2743 Acc: 0.7882\n",
      "Epoch: 6\n",
      "    Phase: train\n",
      "    Phase: validation\n",
      "    Phase: test\n",
      " Loss: 0.2607 Acc: 0.7938\n",
      "Epoch: 7\n",
      "    Phase: train\n",
      "    Phase: validation\n",
      "    Phase: test\n",
      " Loss: 0.2652 Acc: 0.7902\n",
      "Epoch: 8\n",
      "    Phase: train\n",
      "    Phase: validation\n",
      "    Phase: test\n",
      " Loss: 0.2517 Acc: 0.7955\n",
      "Epoch: 9\n",
      "    Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from unet import UNet\n",
    "from train import train\n",
    "from segmentation_metrics import mean_pixel_accuracy, mean_intersection_over_union\n",
    "\n",
    "sweep_config = {\n",
    "  'method': 'bayes',\n",
    "  'metric': {\n",
    "    'name': 'loss',\n",
    "    'goal': 'minimize',\n",
    "  },\n",
    "  'parameters': {\n",
    "    'epochs': {\n",
    "      'value': 15},\n",
    "    'contrast': {\n",
    "      'min': 0.1022,\n",
    "      'max': 0.1236},\n",
    "    'brightness': {\n",
    "      'min': 0.1266,\n",
    "      'max': 0.1666},\n",
    "    'learning_rate': {\n",
    "      'distribution': 'uniform',\n",
    "      'min': 0.00839,\n",
    "      'max': 0.008723\n",
    "    },\n",
    "    \"batch_size\": {\"values\": [14, 12, 10, 8]}\n",
    "  },\n",
    "  'transforms_brightness_and_contrast': True\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"wandb-experiment-sweep\")  \n",
    "\n",
    "# Create a WandB artifact for the model\n",
    "model_artifact = wandb.Artifact(\"my_model\", type=\"model\")\n",
    "\n",
    "unet, losses, accuracies, conf_matrix = None, None, None, None\n",
    "def initiate_training(config: int = None):\n",
    "  global unet, losses, accuracies, conf_matrix\n",
    "  with wandb.init(\n",
    "          # set the wandb project where this run will be logged\n",
    "          project=\"final-project-cvdl\",\n",
    "          name=\"experiment-wandb-specialized\",\n",
    "          # track hyperparameters and run metadata\n",
    "          config=sweep_config):\n",
    "    config = wandb.config\n",
    "\n",
    "    epochs = config.epochs\n",
    "    lr = config.learning_rate\n",
    "    bs = config.batch_size\n",
    "    contrast = config.contrast\n",
    "    brightness = config.brightness\n",
    "\n",
    "    unet = UNet(in_channels=3, out_channels=3, kernel_size=3, features=[64, 128, 256, 512])\n",
    "    losses, accuracies, conf_matrix = train(unet=unet, lr=lr, epochs=epochs, bs=bs, contrast=contrast, brightness=brightness, wandb=wandb)\n",
    "\n",
    "wandb.agent(sweep_id, initiate_training, count=1)\n",
    "\n",
    "# Save the trained PyTorch model to the artifact\n",
    "torch.save(unet.state_dict(), \"my_model.pth\")\n",
    "model_artifact.add_file(\"my_model.pth\")\n",
    "\n",
    "\n",
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-18T17:12:55.023477200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(mean_intersection_over_union(torch.tensor(conf_matrix, dtype=torch.float32)), mean_pixel_accuracy(torch.tensor(conf_matrix, dtype=torch.float32)))\n",
    "print(conf_matrix)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses['train'], label='Training Loss', marker='o')\n",
    "plt.plot(losses['validation'], label='Validation Loss', marker='o')\n",
    "plt.plot(losses['test'], label='Test Loss', marker='o')\n",
    "plt.title('Training, Validation and Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracies['train'], label='Training Accuracy', marker='o')\n",
    "plt.plot(accuracies['validation'], label='Validation Accuracy', marker='o')\n",
    "plt.plot(accuracies['test'], label='Test Accuracy', marker='o')\n",
    "plt.title('Training, Validation and Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.script(unet.to('cpu'))\n",
    "scripted_model.save(\"scripted_unet.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"D:/Users/sonia/Pictures/compressjpeg/WIN_20231124_10_25_34_Pro-min.jpg\").convert('RGB')\n",
    "transform = transforms.ToTensor()\n",
    "input_tensor = transform(image)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(input_tensor.numpy().transpose(1, 2, 0))\n",
    "\n",
    "mean_per_channel = torch.mean(input_tensor, dim=(1, 2))\n",
    "std_per_channel = torch.std(input_tensor, dim=(1, 2))\n",
    "preprocess = transforms.Compose([\n",
    "  transforms.Resize(256),\n",
    "  transforms.CenterCrop(224),\n",
    "  transforms.Normalize(mean=mean_per_channel, std=std_per_channel),\n",
    "\n",
    "  v2.RandomRotation(degrees=45),\n",
    "  v2.RandomHorizontalFlip(),\n",
    "  # v2.ColorJitter(brightness= 0.18218726522564344,contrast=0.10838793459639176),\n",
    "])\n",
    "input_tensor = preprocess(input_tensor)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "  output = unet(input_batch)\n",
    "  \n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(input_tensor.numpy().transpose(1, 2, 0))\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(unet.true_segmentation(output[0]).numpy(), cmap=\"gray\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
